# awesome-nlp-and-xai

## Transformers

### 1. Encoder Only

### 2. Decoder Only

### 3. Encoder + Decoder

### Wait for arrangement

Switch Transformers: Scaling To Trillion Parameter Models With Simple and Efficient Sparsity ([pdf](https://arxiv.org/pdf/2101.03961.pdf), code)

2. 
